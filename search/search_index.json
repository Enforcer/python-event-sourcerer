{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Python Event Sourcery A library for event-based systems in Python. For event sourcing, CQRS, and event-driven architectures.","title":"Event Sourcery"},{"location":"#python-event-sourcery","text":"A library for event-based systems in Python. For event sourcing, CQRS, and event-driven architectures.","title":"Python Event Sourcery"},{"location":"basics/","text":"Basics What is an event? An event is a change of state. It is a piece of information stating a fact with extra information, letting to say what just actually happened and, potentially, react to it. Since events merely state the fact, that something happened, we write them in past tense. Examples Sprint started Payment failed Order cancelled Invoice issued You can stop reading for a moment and think about examples from the projects you're working on. When an event occurs it cannot be denied anymore. It can be only reacted to. Let's say that the payment failed but for some reason it should not. We can not negate the event, but we can always try to e.g. pay with another payment card. This is an example of reacting to an event. In an application that uses events explicitly, they will somehow be represented in the source code. They can be coded as simple data structures: @dataclass class SprintStarted : when_started : datetime when_ends : datetime project_key : ProjectKey How Event Sourcery helps with using events? Event Sourcery provides a simple base class that is currently using Pydantic . It brings all goodies of that library plus provides a few basic fields, like unique identifier of an event or timestamp of event creation. from event_sourcery import Event class SprintStarted ( Event ): when_started : datetime when_ends : datetime project_key : ProjectKey event = SprintStarted ( when_started = datetime . now (), when_ends = datetime . now () + timedelta ( days = 7 ), project_key = \"PRO\" , ) # SprintStarted( # uuid=UUID('48c3ecb1-2d58-4b99-b964-2fb9ccfba601'), # created_at=datetime.datetime(2022, 8, 7, 16, 56, 35, 719248), # when_started=datetime.datetime(2022, 8, 7, 18, 56, 35, 719177), # when_ends=datetime.datetime(2022, 8, 14, 18, 56, 35, 719184), # project_key='PRO' # ) Other baked-in feature includes tracing ids - correlation id and causation id, useful for tracking flows of events in the system. What is Event-Driven Architecture? Systems that use Event-Driven Architecture (or EDA in short) use events for connecting its parts. One part of the system publishes an event, letting all other interested parts know that something significant happened. In turn, these parts may trigger some action on their side. This pattern is used with microservices publishing events via brokers, such as RabbitMQ or Apache Kafka . Event-Driven Distributed App Integration with events is a pattern that makes publishing part of the system ignorant of other parts, so there's loose coupling between them. For example, Order Service does not have to know that Payment Service or Invoice Service even exists. Another benefit from asynchronous, event-driven architecture is that even if something is temporarily wrong with Payment Service , system can still operate. Broker will receive messages and once Payment Service is back online, the process can continue. The same integration method can be used in much simpler environments, e.g. monorepo applications. One doesn't need a broker right away. How Event Sourcery helps with that? Event Sourcery provides implementation of Event Store and so-called Outbox. The former is a class to provide persistence of events while the Outbox makes sure they will be published eventually, even if there's something with the broker. First thing is to ask Event Store to not only save the event, but also to put it in the Outbox. You can do it using publish method instead of append . an_event = SomeEvent ( first_name = \"John\" ) # publish additionally puts an event in outbox event_store . append ( stream_id = uuid4 (), events = [ an_event ]) Then, one has to implement publishing mechanism - e.g. publishing to Kafka or RabbitMQ, depending on your stack. Event Sourcery does not provide this out of the box. What it does provide is Outbox class that accepts publisher argument to send the message. from event_sourcery import get_outbox outbox = get_outbox ( session = session , # SQLAlchemy session # a function that receives published event and does something with it publisher = lambda event : print ( event ), ) The last step is to run Outbox in a separate process, e.g. separate docker container in an infinite loop: while True : try : outbox . run_once () session . commit () except : session . rollback () logger . exception ( \"Outbox processing failed\" ) time . sleep ( 5 ) Regarding the simpler variant - that is monorepo app, running in a single process - Event Sourcery has a system of synchronous subscriptions. Simply saying, we can set up callbacks that will be triggered once a certain event is saved. store = get_event_store ( session = session , subscriptions = { UserRegistered : [ lambda event : send_email ( event . email )], }, ) stream_id = uuid4 () event = UserRegistered ( email = \"test@example.com\" ) store . append ( stream_id = stream_id , events = [ event ]) # here, callback runs and email gets sent! What is Event Sourcing? Recall any entity/model/being from a piece of software you recently worked on. Let's consider e-commerce Order . It might hold current status (new, confirmed, shipped, etc) and summaries \u2013 total price, shipping and taxes. Naturally, Order does not exist on its own. We usually wire it with another entity, OrderLine , that refers to a single product ordered with a quantity information. This structure could be represented in a relational database in a following way: orders id status total_price 1 new 169.99 order_lines id order_id product_id quantity 1 1 512 1 2 1 614 3 By storing data this way we can always cheaply get CURRENT state of our Order . We store a dump of serialized object after latest changes. Changing anything, for example switching status from new to shipped causes data overwrite. We irreversibly lose old state. What if we need to track all changes? Let\u2019s see how that fits in another database table: order_history id order_id event_name datetime data 1 1 OrderCreated 2018-01-20 18:33:12 2 1 LineAdded 2018-01-20 18:33:44 {\"product_id\": 512, \"quantity\": 1} 3 1 StatusChanged 2018-01-20 18:42:59 {\"status\": \"confirmed\"} Such a representation enables us to confidently say what was changed and when. But this order_history table plays only a second fiddle. It is merely an extra record of Order , added just to fulfill some business requirement. We still reach to original orders table when we want to know exact state of any Order in all other scenarios. However, notice that order_history is as good as orders table when we have to get current Order state. How so? We just have to fetch all entries for given Order and replay them from the start. In the end we\u2019ll get exactly the same information that is saved in orders table. So do we even need orders and orders_lines table as a source of truth...? Event Sourcing proposes we don't. We can still keep them around to optimize reading data for UI, but no longer have to rely on it in any situation that would actually change Order . To sum up, Event Sourcing comes down to: Keeping your business objects (called aggregates) as a series of replayable events. This is often called an event stream. Never deleting any events from a system, only appending new ones Using events as the only reliable way of telling in what state a given aggregate is If you need to query data or present them in a table-like format, keep a copy of them in a denormalized format. This is called projection Designing your aggregates to protect certain vital business invariants, such as Order encapsulates costs summary. A good rule of thumb is to keep aggregates as small as possible How Event Sourcery helps with that? Event Sourcery provides a base class for an aggregate and repository implementation that makes it much easy to create or read/change aggregates. class LightSwitch ( Aggregate ): \"\"\"A simple aggregate that models a light switch.\"\"\" class AlreadyTurnedOn ( Exception ): pass class AlreadyTurnedOff ( Exception ): pass def __init__ ( self , past_events : list [ Event ], changes : list [ Event ], stream_id : StreamId ) -> None : # init any state you need in aggregate class to check conditions self . _shines = False # required for base class super () . __init__ ( past_events , changes , stream_id ) def _apply ( self , event : Event ) -> None : # each aggregate need an _apply method to parse events match event : case TurnedOn () as event : self . _shines = True case TurnedOff () as event : self . _shines = False def turn_on ( self ) -> None : # this is one of command methods # we can rejest it (i.e. raise an exception) # if current state does not allow this to proceed # e.g. light is already on if self . _shines : raise LightSwitch . AlreadyTurnedOn self . _event ( TurnedOn ) def turn_off ( self ) -> None : if not self . _shines : raise LightSwitch . AlreadyTurnedOff self . _event ( TurnedOff ) To create a Repository tailored for a particular Aggregate class, we need that class and Event Store instance: repository = Repository [ LightSwitch ]( event_store , LightSwitch ) A Repository exposes method to create a new instance of Aggregate: stream_id = uuid4 () with repository . new ( stream_id = stream_id ) as switch : switch . turn_on () ...or to work with existing Aggregate, making sure changes are saved at the end: with repository . aggregate ( stream_id = stream_id ) as switch_second_incarnation : try : switch_second_incarnation . turn_on () except LightSwitch . AlreadyTurnedOn : # o mon Dieu, I made a mistake! switch_second_incarnation . turn_off () A Repository is a thin wrapper over Event Store. One can also write Aggregates even without using our base class and use EventStore directly!","title":"Basics"},{"location":"basics/#basics","text":"","title":"Basics"},{"location":"basics/#what-is-an-event","text":"An event is a change of state. It is a piece of information stating a fact with extra information, letting to say what just actually happened and, potentially, react to it. Since events merely state the fact, that something happened, we write them in past tense. Examples Sprint started Payment failed Order cancelled Invoice issued You can stop reading for a moment and think about examples from the projects you're working on. When an event occurs it cannot be denied anymore. It can be only reacted to. Let's say that the payment failed but for some reason it should not. We can not negate the event, but we can always try to e.g. pay with another payment card. This is an example of reacting to an event. In an application that uses events explicitly, they will somehow be represented in the source code. They can be coded as simple data structures: @dataclass class SprintStarted : when_started : datetime when_ends : datetime project_key : ProjectKey","title":"What is an event?"},{"location":"basics/#how-event-sourcery-helps-with-using-events","text":"Event Sourcery provides a simple base class that is currently using Pydantic . It brings all goodies of that library plus provides a few basic fields, like unique identifier of an event or timestamp of event creation. from event_sourcery import Event class SprintStarted ( Event ): when_started : datetime when_ends : datetime project_key : ProjectKey event = SprintStarted ( when_started = datetime . now (), when_ends = datetime . now () + timedelta ( days = 7 ), project_key = \"PRO\" , ) # SprintStarted( # uuid=UUID('48c3ecb1-2d58-4b99-b964-2fb9ccfba601'), # created_at=datetime.datetime(2022, 8, 7, 16, 56, 35, 719248), # when_started=datetime.datetime(2022, 8, 7, 18, 56, 35, 719177), # when_ends=datetime.datetime(2022, 8, 14, 18, 56, 35, 719184), # project_key='PRO' # ) Other baked-in feature includes tracing ids - correlation id and causation id, useful for tracking flows of events in the system.","title":"How Event Sourcery helps with using events?"},{"location":"basics/#what-is-event-driven-architecture","text":"Systems that use Event-Driven Architecture (or EDA in short) use events for connecting its parts. One part of the system publishes an event, letting all other interested parts know that something significant happened. In turn, these parts may trigger some action on their side. This pattern is used with microservices publishing events via brokers, such as RabbitMQ or Apache Kafka . Event-Driven Distributed App Integration with events is a pattern that makes publishing part of the system ignorant of other parts, so there's loose coupling between them. For example, Order Service does not have to know that Payment Service or Invoice Service even exists. Another benefit from asynchronous, event-driven architecture is that even if something is temporarily wrong with Payment Service , system can still operate. Broker will receive messages and once Payment Service is back online, the process can continue. The same integration method can be used in much simpler environments, e.g. monorepo applications. One doesn't need a broker right away.","title":"What is Event-Driven Architecture?"},{"location":"basics/#how-event-sourcery-helps-with-that","text":"Event Sourcery provides implementation of Event Store and so-called Outbox. The former is a class to provide persistence of events while the Outbox makes sure they will be published eventually, even if there's something with the broker. First thing is to ask Event Store to not only save the event, but also to put it in the Outbox. You can do it using publish method instead of append . an_event = SomeEvent ( first_name = \"John\" ) # publish additionally puts an event in outbox event_store . append ( stream_id = uuid4 (), events = [ an_event ]) Then, one has to implement publishing mechanism - e.g. publishing to Kafka or RabbitMQ, depending on your stack. Event Sourcery does not provide this out of the box. What it does provide is Outbox class that accepts publisher argument to send the message. from event_sourcery import get_outbox outbox = get_outbox ( session = session , # SQLAlchemy session # a function that receives published event and does something with it publisher = lambda event : print ( event ), ) The last step is to run Outbox in a separate process, e.g. separate docker container in an infinite loop: while True : try : outbox . run_once () session . commit () except : session . rollback () logger . exception ( \"Outbox processing failed\" ) time . sleep ( 5 ) Regarding the simpler variant - that is monorepo app, running in a single process - Event Sourcery has a system of synchronous subscriptions. Simply saying, we can set up callbacks that will be triggered once a certain event is saved. store = get_event_store ( session = session , subscriptions = { UserRegistered : [ lambda event : send_email ( event . email )], }, ) stream_id = uuid4 () event = UserRegistered ( email = \"test@example.com\" ) store . append ( stream_id = stream_id , events = [ event ]) # here, callback runs and email gets sent!","title":"How Event Sourcery helps with that?"},{"location":"basics/#what-is-event-sourcing","text":"Recall any entity/model/being from a piece of software you recently worked on. Let's consider e-commerce Order . It might hold current status (new, confirmed, shipped, etc) and summaries \u2013 total price, shipping and taxes. Naturally, Order does not exist on its own. We usually wire it with another entity, OrderLine , that refers to a single product ordered with a quantity information. This structure could be represented in a relational database in a following way: orders id status total_price 1 new 169.99 order_lines id order_id product_id quantity 1 1 512 1 2 1 614 3 By storing data this way we can always cheaply get CURRENT state of our Order . We store a dump of serialized object after latest changes. Changing anything, for example switching status from new to shipped causes data overwrite. We irreversibly lose old state. What if we need to track all changes? Let\u2019s see how that fits in another database table: order_history id order_id event_name datetime data 1 1 OrderCreated 2018-01-20 18:33:12 2 1 LineAdded 2018-01-20 18:33:44 {\"product_id\": 512, \"quantity\": 1} 3 1 StatusChanged 2018-01-20 18:42:59 {\"status\": \"confirmed\"} Such a representation enables us to confidently say what was changed and when. But this order_history table plays only a second fiddle. It is merely an extra record of Order , added just to fulfill some business requirement. We still reach to original orders table when we want to know exact state of any Order in all other scenarios. However, notice that order_history is as good as orders table when we have to get current Order state. How so? We just have to fetch all entries for given Order and replay them from the start. In the end we\u2019ll get exactly the same information that is saved in orders table. So do we even need orders and orders_lines table as a source of truth...? Event Sourcing proposes we don't. We can still keep them around to optimize reading data for UI, but no longer have to rely on it in any situation that would actually change Order . To sum up, Event Sourcing comes down to: Keeping your business objects (called aggregates) as a series of replayable events. This is often called an event stream. Never deleting any events from a system, only appending new ones Using events as the only reliable way of telling in what state a given aggregate is If you need to query data or present them in a table-like format, keep a copy of them in a denormalized format. This is called projection Designing your aggregates to protect certain vital business invariants, such as Order encapsulates costs summary. A good rule of thumb is to keep aggregates as small as possible","title":"What is Event Sourcing?"},{"location":"basics/#how-event-sourcery-helps-with-that_1","text":"Event Sourcery provides a base class for an aggregate and repository implementation that makes it much easy to create or read/change aggregates. class LightSwitch ( Aggregate ): \"\"\"A simple aggregate that models a light switch.\"\"\" class AlreadyTurnedOn ( Exception ): pass class AlreadyTurnedOff ( Exception ): pass def __init__ ( self , past_events : list [ Event ], changes : list [ Event ], stream_id : StreamId ) -> None : # init any state you need in aggregate class to check conditions self . _shines = False # required for base class super () . __init__ ( past_events , changes , stream_id ) def _apply ( self , event : Event ) -> None : # each aggregate need an _apply method to parse events match event : case TurnedOn () as event : self . _shines = True case TurnedOff () as event : self . _shines = False def turn_on ( self ) -> None : # this is one of command methods # we can rejest it (i.e. raise an exception) # if current state does not allow this to proceed # e.g. light is already on if self . _shines : raise LightSwitch . AlreadyTurnedOn self . _event ( TurnedOn ) def turn_off ( self ) -> None : if not self . _shines : raise LightSwitch . AlreadyTurnedOff self . _event ( TurnedOff ) To create a Repository tailored for a particular Aggregate class, we need that class and Event Store instance: repository = Repository [ LightSwitch ]( event_store , LightSwitch ) A Repository exposes method to create a new instance of Aggregate: stream_id = uuid4 () with repository . new ( stream_id = stream_id ) as switch : switch . turn_on () ...or to work with existing Aggregate, making sure changes are saved at the end: with repository . aggregate ( stream_id = stream_id ) as switch_second_incarnation : try : switch_second_incarnation . turn_on () except LightSwitch . AlreadyTurnedOn : # o mon Dieu, I made a mistake! switch_second_incarnation . turn_off () A Repository is a thin wrapper over Event Store. One can also write Aggregates even without using our base class and use EventStore directly!","title":"How Event Sourcery helps with that?"},{"location":"features/","text":"Features Building app using Event-Driven Architecture Event base class using Pydantic for easy (de)serialization Event Store to persist events Synchronous subscriptions based on callbacks run in the same process Outbox pattern outline to integrate with broker of choice Event Sourcing Persistence of event streams using Event Store Snapshots support Base Aggregate class Repository implementation with optimistic concurrency control out of the box Advanced Interchangeability of storage backend - you can write your own Using any classes as events with custom event registry and (de)serialization Standing on shoulders of giants SQLAlchemy Pydantic Rails Event Store Marten","title":"Features"},{"location":"features/#features","text":"","title":"Features"},{"location":"features/#building-app-using-event-driven-architecture","text":"Event base class using Pydantic for easy (de)serialization Event Store to persist events Synchronous subscriptions based on callbacks run in the same process Outbox pattern outline to integrate with broker of choice","title":"Building app using Event-Driven Architecture"},{"location":"features/#event-sourcing","text":"Persistence of event streams using Event Store Snapshots support Base Aggregate class Repository implementation with optimistic concurrency control out of the box","title":"Event Sourcing"},{"location":"features/#advanced","text":"Interchangeability of storage backend - you can write your own Using any classes as events with custom event registry and (de)serialization","title":"Advanced"},{"location":"features/#standing-on-shoulders-of-giants","text":"SQLAlchemy Pydantic Rails Event Store Marten","title":"Standing on shoulders of giants"},{"location":"reference/","text":"API Reference","title":"API Reference"},{"location":"reference/#api-reference","text":"","title":"API Reference"},{"location":"reference/backend_factory/","text":"Bases: ABC Abstract base class to configure EventStore. Source code in event_sourcery/event_store/factory.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 class BackendFactory ( abc . ABC ): \"\"\"Abstract base class to configure EventStore.\"\"\" @abc . abstractmethod def build ( self ) -> Backend : pass @abc . abstractmethod def with_event_registry ( self , event_registry : EventRegistry ) -> Self : pass @abc . abstractmethod def with_outbox ( self , filterer : OutboxFiltererStrategy = no_filter ) -> Self : pass @abc . abstractmethod def without_outbox ( self , filterer : OutboxFiltererStrategy = no_filter ) -> Self : pass","title":"BackendFactory"},{"location":"reference/event/","text":"Bases: BaseModel Base class for all events. Example usage: class OrderCancelled(Event): order_id: OrderId Source code in event_sourcery/event_store/event/dto.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 class Event ( BaseModel , extra = \"forbid\" ): \"\"\"Base class for all events. Example usage: ``` class OrderCancelled(Event): order_id: OrderId ``` \"\"\" __registry__ : ClassVar = EventRegistry () def __init_subclass__ ( cls , ** kwargs : Any ) -> None : cls . __registry__ . add ( cls )","title":"Event"},{"location":"reference/event_registry/","text":"Keeps mappings between event types and their names. Normally, there is no need to use it directly. If one needs to have multiple registries or wants more granular control, they can pass an instance of EventRegistry to BackendFactory. Source code in event_sourcery/event_store/event/registry.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 class EventRegistry : \"\"\"Keeps mappings between event types and their names. Normally, there is no need to use it directly. If one needs to have multiple registries or wants more granular control, they can pass an instance of EventRegistry to BackendFactory.\"\"\" def __init__ ( self ) -> None : self . _types_to_names : dict [ type [ Event ], str ] = {} self . _names_to_types : dict [ str , type [ Event ]] = {} def add ( self , event : type [ \"Event\" ]) -> type [ \"Event\" ]: \"\"\"Add event subclass to the registry.\"\"\" if event in self . _types_to_names : raise DuplicatedEvent ( f \"Duplicated Event detected! { event } \" ) name = event_name ( event ) if name in self . _names_to_types : raise DuplicatedEvent ( f \"Duplicated Event name detected! { name } \" ) self . _types_to_names [ event ] = name self . _names_to_types [ name ] = event return event # for use as a decorator def type_for_name ( self , name : str ) -> type [ \"Event\" ]: return self . _names_to_types [ name ] def name_for_type ( self , event : type [ \"Event\" ]) -> str : return self . _types_to_names [ event ] add ( event ) Add event subclass to the registry. Source code in event_sourcery/event_store/event/registry.py 31 32 33 34 35 36 37 38 39 40 41 42 def add ( self , event : type [ \"Event\" ]) -> type [ \"Event\" ]: \"\"\"Add event subclass to the registry.\"\"\" if event in self . _types_to_names : raise DuplicatedEvent ( f \"Duplicated Event detected! { event } \" ) name = event_name ( event ) if name in self . _names_to_types : raise DuplicatedEvent ( f \"Duplicated Event name detected! { name } \" ) self . _types_to_names [ event ] = name self . _names_to_types [ name ] = event return event # for use as a decorator","title":"EventRegistry"},{"location":"reference/event_registry/#event_sourcery.event_store.EventRegistry.add","text":"Add event subclass to the registry. Source code in event_sourcery/event_store/event/registry.py 31 32 33 34 35 36 37 38 39 40 41 42 def add ( self , event : type [ \"Event\" ]) -> type [ \"Event\" ]: \"\"\"Add event subclass to the registry.\"\"\" if event in self . _types_to_names : raise DuplicatedEvent ( f \"Duplicated Event detected! { event } \" ) name = event_name ( event ) if name in self . _names_to_types : raise DuplicatedEvent ( f \"Duplicated Event name detected! { name } \" ) self . _types_to_names [ event ] = name self . _names_to_types [ name ] = event return event # for use as a decorator","title":"add"},{"location":"reference/event_store/","text":"API for working with events. Source code in event_sourcery/event_store/event_store.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 class EventStore : \"\"\"API for working with events.\"\"\" def __init__ ( self , storage_strategy : StorageStrategy , serde : Serde ) -> None : self . _storage_strategy = storage_strategy self . _serde = serde def load_stream ( self , stream_id : StreamId , start : int | None = None , stop : int | None = None , ) -> Sequence [ WrappedEvent ]: \"\"\"Loads events from a given stream. Examples: >>> load_stream(stream_id=StreamId(name=\"not_existing_stream\")) [] >>> load_stream(stream_id=StreamId(name=\"existing_stream\")) [WrappedEvent(..., version=1), ..., WrappedEvent(..., version=3)] >>> load_stream(stream_id=StreamId(name=\"existing_stream\"), start=2, stop=3) [WrappedEvent(..., version=2)] Args: stream_id: The stream identifier to load events from. start: The stream version to start loading from (including). stop: The stream version to stop loading at (excluding). Returns: A sequence of events or empty list if the stream doesn't exist. \"\"\" events = self . _storage_strategy . fetch_events ( stream_id , start = start , stop = stop ) return self . _deserialize_events ( events ) @singledispatchmethod def append ( self , first : WrappedEvent , * events : WrappedEvent , stream_id : StreamId , expected_version : int | Versioning = 0 , ) -> None : \"\"\"Appends events to a stream with a given ID. Implements optimistic locking to ensure stream wasn't modified since last read. To use it, pass the expected version of the stream. Examples: >>> append(WrappedEvent(...), stream_id=StreamId()) None >>> append(WrappedEvent(...), stream_id=StreamId(), expected_version=1) None Args: first: The first event to append (WrappedEvent or Event). *events: The rest of the events to append (same type as first argument). stream_id: The stream identifier to append events to. expected_version: The expected version of the stream Returns: None \"\"\" self . _append ( stream_id = stream_id , events = ( first , * events ), expected_version = expected_version , ) @append . register def _append_events ( self , * events : Event , stream_id : StreamId , expected_version : int | Versioning = 0 , ) -> None : wrapped_events = self . _wrap_events ( expected_version , events ) self . append ( * wrapped_events , stream_id = stream_id , expected_version = expected_version , ) @singledispatchmethod def _wrap_events ( self , expected_version : int , events : Sequence [ Event ], ) -> Sequence [ WrappedEvent ]: return [ WrappedEvent . wrap ( event = event , version = version ) for version , event in enumerate ( events , start = expected_version + 1 ) ] @_wrap_events . register def _wrap_events_versioning ( self , expected_version : Versioning , events : Sequence [ Event ] ) -> Sequence [ WrappedEvent ]: return [ WrappedEvent . wrap ( event = event , version = None ) for event in events ] def _append ( self , stream_id : StreamId , events : Sequence [ WrappedEvent ], expected_version : int | Versioning , ) -> None : new_version = events [ - 1 ] . version versioning : Versioning if expected_version is not NO_VERSIONING : versioning = ExplicitVersioning ( expected_version = cast ( int , expected_version ), initial_version = cast ( int , new_version ), ) else : versioning = NO_VERSIONING self . _storage_strategy . insert_events ( stream_id = stream_id , versioning = versioning , events = self . _serialize_events ( events , stream_id ), ) def delete_stream ( self , stream_id : StreamId ) -> None : \"\"\"Deletes a stream with a given ID. If a stream does not exist, this method does nothing. Examples: >>> delete_stream(StreamId()) None >>> delete_stream(StreamId(name=\"not_existing_stream\")) None Args: stream_id: The stream identifier to delete. Returns: None \"\"\" self . _storage_strategy . delete_stream ( stream_id ) def save_snapshot ( self , stream_id : StreamId , snapshot : WrappedEvent ) -> None : \"\"\"Saves a snapshot of the stream. Examples: >>> save_snapshot(StreamId(), WrappedEvent(...)) None >>> save_snapshot(StreamId(name=\"not_existing_stream\"), WrappedEvent(...)) None Args: stream_id: The stream identifier to save the snapshot. snapshot: The snapshot to save. Returns: None \"\"\" serialized = self . _serde . serialize ( event = snapshot , stream_id = stream_id ) self . _storage_strategy . save_snapshot ( serialized ) def _deserialize_events ( self , events : list [ RawEvent ]) -> list [ WrappedEvent ]: return [ self . _serde . deserialize ( e ) for e in events ] def _serialize_events ( self , events : Sequence [ WrappedEvent ], stream_id : StreamId , ) -> list [ RawEvent ]: return [ self . _serde . serialize ( event = e , stream_id = stream_id ) for e in events ] @property def position ( self ) -> Position | None : \"\"\"Returns the current position of the event store. Examples: >>> position None # nothing was saved yet >>> position Position(15) # Some events were saved \"\"\" return self . _storage_strategy . current_position position : Position | None property Returns the current position of the event store. Examples: >>> position None # nothing was saved yet >>> position Position(15) # Some events were saved append ( first , * events , stream_id , expected_version = 0 ) Appends events to a stream with a given ID. Implements optimistic locking to ensure stream wasn't modified since last read. To use it, pass the expected version of the stream. Examples: >>> append ( WrappedEvent ( ... ), stream_id = StreamId ()) None >>> append ( WrappedEvent ( ... ), stream_id = StreamId (), expected_version = 1 ) None Parameters: Name Type Description Default first WrappedEvent The first event to append (WrappedEvent or Event). required *events WrappedEvent The rest of the events to append (same type as first argument). () stream_id StreamId The stream identifier to append events to. required expected_version int | Versioning The expected version of the stream 0 Returns: Type Description None None Source code in event_sourcery/event_store/event_store.py 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 @singledispatchmethod def append ( self , first : WrappedEvent , * events : WrappedEvent , stream_id : StreamId , expected_version : int | Versioning = 0 , ) -> None : \"\"\"Appends events to a stream with a given ID. Implements optimistic locking to ensure stream wasn't modified since last read. To use it, pass the expected version of the stream. Examples: >>> append(WrappedEvent(...), stream_id=StreamId()) None >>> append(WrappedEvent(...), stream_id=StreamId(), expected_version=1) None Args: first: The first event to append (WrappedEvent or Event). *events: The rest of the events to append (same type as first argument). stream_id: The stream identifier to append events to. expected_version: The expected version of the stream Returns: None \"\"\" self . _append ( stream_id = stream_id , events = ( first , * events ), expected_version = expected_version , ) delete_stream ( stream_id ) Deletes a stream with a given ID. If a stream does not exist, this method does nothing. Examples: >>> delete_stream ( StreamId ()) None >>> delete_stream ( StreamId ( name = \"not_existing_stream\" )) None Parameters: Name Type Description Default stream_id StreamId The stream identifier to delete. required Returns: Type Description None None Source code in event_sourcery/event_store/event_store.py 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 def delete_stream ( self , stream_id : StreamId ) -> None : \"\"\"Deletes a stream with a given ID. If a stream does not exist, this method does nothing. Examples: >>> delete_stream(StreamId()) None >>> delete_stream(StreamId(name=\"not_existing_stream\")) None Args: stream_id: The stream identifier to delete. Returns: None \"\"\" self . _storage_strategy . delete_stream ( stream_id ) load_stream ( stream_id , start = None , stop = None ) Loads events from a given stream. Examples: >>> load_stream ( stream_id = StreamId ( name = \"not_existing_stream\" )) [] >>> load_stream ( stream_id = StreamId ( name = \"existing_stream\" )) [WrappedEvent(..., version=1), ..., WrappedEvent(..., version=3)] >>> load_stream ( stream_id = StreamId ( name = \"existing_stream\" ), start = 2 , stop = 3 ) [WrappedEvent(..., version=2)] Parameters: Name Type Description Default stream_id StreamId The stream identifier to load events from. required start int | None The stream version to start loading from (including). None stop int | None The stream version to stop loading at (excluding). None Returns: Type Description Sequence [ WrappedEvent ] A sequence of events or empty list if the stream doesn't exist. Source code in event_sourcery/event_store/event_store.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 def load_stream ( self , stream_id : StreamId , start : int | None = None , stop : int | None = None , ) -> Sequence [ WrappedEvent ]: \"\"\"Loads events from a given stream. Examples: >>> load_stream(stream_id=StreamId(name=\"not_existing_stream\")) [] >>> load_stream(stream_id=StreamId(name=\"existing_stream\")) [WrappedEvent(..., version=1), ..., WrappedEvent(..., version=3)] >>> load_stream(stream_id=StreamId(name=\"existing_stream\"), start=2, stop=3) [WrappedEvent(..., version=2)] Args: stream_id: The stream identifier to load events from. start: The stream version to start loading from (including). stop: The stream version to stop loading at (excluding). Returns: A sequence of events or empty list if the stream doesn't exist. \"\"\" events = self . _storage_strategy . fetch_events ( stream_id , start = start , stop = stop ) return self . _deserialize_events ( events ) save_snapshot ( stream_id , snapshot ) Saves a snapshot of the stream. Examples: >>> save_snapshot ( StreamId (), WrappedEvent ( ... )) None >>> save_snapshot ( StreamId ( name = \"not_existing_stream\" ), WrappedEvent ( ... )) None Parameters: Name Type Description Default stream_id StreamId The stream identifier to save the snapshot. required snapshot WrappedEvent The snapshot to save. required Returns: Type Description None None Source code in event_sourcery/event_store/event_store.py 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 def save_snapshot ( self , stream_id : StreamId , snapshot : WrappedEvent ) -> None : \"\"\"Saves a snapshot of the stream. Examples: >>> save_snapshot(StreamId(), WrappedEvent(...)) None >>> save_snapshot(StreamId(name=\"not_existing_stream\"), WrappedEvent(...)) None Args: stream_id: The stream identifier to save the snapshot. snapshot: The snapshot to save. Returns: None \"\"\" serialized = self . _serde . serialize ( event = snapshot , stream_id = stream_id ) self . _storage_strategy . save_snapshot ( serialized )","title":"Event Store"},{"location":"reference/event_store/#event_sourcery.event_store.event_store.EventStore.position","text":"Returns the current position of the event store. Examples: >>> position None # nothing was saved yet >>> position Position(15) # Some events were saved","title":"position"},{"location":"reference/event_store/#event_sourcery.event_store.event_store.EventStore.append","text":"Appends events to a stream with a given ID. Implements optimistic locking to ensure stream wasn't modified since last read. To use it, pass the expected version of the stream. Examples: >>> append ( WrappedEvent ( ... ), stream_id = StreamId ()) None >>> append ( WrappedEvent ( ... ), stream_id = StreamId (), expected_version = 1 ) None Parameters: Name Type Description Default first WrappedEvent The first event to append (WrappedEvent or Event). required *events WrappedEvent The rest of the events to append (same type as first argument). () stream_id StreamId The stream identifier to append events to. required expected_version int | Versioning The expected version of the stream 0 Returns: Type Description None None Source code in event_sourcery/event_store/event_store.py 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 @singledispatchmethod def append ( self , first : WrappedEvent , * events : WrappedEvent , stream_id : StreamId , expected_version : int | Versioning = 0 , ) -> None : \"\"\"Appends events to a stream with a given ID. Implements optimistic locking to ensure stream wasn't modified since last read. To use it, pass the expected version of the stream. Examples: >>> append(WrappedEvent(...), stream_id=StreamId()) None >>> append(WrappedEvent(...), stream_id=StreamId(), expected_version=1) None Args: first: The first event to append (WrappedEvent or Event). *events: The rest of the events to append (same type as first argument). stream_id: The stream identifier to append events to. expected_version: The expected version of the stream Returns: None \"\"\" self . _append ( stream_id = stream_id , events = ( first , * events ), expected_version = expected_version , )","title":"append"},{"location":"reference/event_store/#event_sourcery.event_store.event_store.EventStore.delete_stream","text":"Deletes a stream with a given ID. If a stream does not exist, this method does nothing. Examples: >>> delete_stream ( StreamId ()) None >>> delete_stream ( StreamId ( name = \"not_existing_stream\" )) None Parameters: Name Type Description Default stream_id StreamId The stream identifier to delete. required Returns: Type Description None None Source code in event_sourcery/event_store/event_store.py 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 def delete_stream ( self , stream_id : StreamId ) -> None : \"\"\"Deletes a stream with a given ID. If a stream does not exist, this method does nothing. Examples: >>> delete_stream(StreamId()) None >>> delete_stream(StreamId(name=\"not_existing_stream\")) None Args: stream_id: The stream identifier to delete. Returns: None \"\"\" self . _storage_strategy . delete_stream ( stream_id )","title":"delete_stream"},{"location":"reference/event_store/#event_sourcery.event_store.event_store.EventStore.load_stream","text":"Loads events from a given stream. Examples: >>> load_stream ( stream_id = StreamId ( name = \"not_existing_stream\" )) [] >>> load_stream ( stream_id = StreamId ( name = \"existing_stream\" )) [WrappedEvent(..., version=1), ..., WrappedEvent(..., version=3)] >>> load_stream ( stream_id = StreamId ( name = \"existing_stream\" ), start = 2 , stop = 3 ) [WrappedEvent(..., version=2)] Parameters: Name Type Description Default stream_id StreamId The stream identifier to load events from. required start int | None The stream version to start loading from (including). None stop int | None The stream version to stop loading at (excluding). None Returns: Type Description Sequence [ WrappedEvent ] A sequence of events or empty list if the stream doesn't exist. Source code in event_sourcery/event_store/event_store.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 def load_stream ( self , stream_id : StreamId , start : int | None = None , stop : int | None = None , ) -> Sequence [ WrappedEvent ]: \"\"\"Loads events from a given stream. Examples: >>> load_stream(stream_id=StreamId(name=\"not_existing_stream\")) [] >>> load_stream(stream_id=StreamId(name=\"existing_stream\")) [WrappedEvent(..., version=1), ..., WrappedEvent(..., version=3)] >>> load_stream(stream_id=StreamId(name=\"existing_stream\"), start=2, stop=3) [WrappedEvent(..., version=2)] Args: stream_id: The stream identifier to load events from. start: The stream version to start loading from (including). stop: The stream version to stop loading at (excluding). Returns: A sequence of events or empty list if the stream doesn't exist. \"\"\" events = self . _storage_strategy . fetch_events ( stream_id , start = start , stop = stop ) return self . _deserialize_events ( events )","title":"load_stream"},{"location":"reference/event_store/#event_sourcery.event_store.event_store.EventStore.save_snapshot","text":"Saves a snapshot of the stream. Examples: >>> save_snapshot ( StreamId (), WrappedEvent ( ... )) None >>> save_snapshot ( StreamId ( name = \"not_existing_stream\" ), WrappedEvent ( ... )) None Parameters: Name Type Description Default stream_id StreamId The stream identifier to save the snapshot. required snapshot WrappedEvent The snapshot to save. required Returns: Type Description None None Source code in event_sourcery/event_store/event_store.py 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 def save_snapshot ( self , stream_id : StreamId , snapshot : WrappedEvent ) -> None : \"\"\"Saves a snapshot of the stream. Examples: >>> save_snapshot(StreamId(), WrappedEvent(...)) None >>> save_snapshot(StreamId(name=\"not_existing_stream\"), WrappedEvent(...)) None Args: stream_id: The stream identifier to save the snapshot. snapshot: The snapshot to save. Returns: None \"\"\" serialized = self . _serde . serialize ( event = snapshot , stream_id = stream_id ) self . _storage_strategy . save_snapshot ( serialized )","title":"save_snapshot"},{"location":"reference/in_memory_backend_factory/","text":"Bases: BackendFactory Lightweight in-memory backend factory for testing and development. Source code in event_sourcery/event_store/in_memory.py 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 @dataclass ( repr = False ) class InMemoryBackendFactory ( BackendFactory ): \"\"\"Lightweight in-memory backend factory for testing and development.\"\"\" serde = Serde ( Event . __registry__ ) _config : Config = field ( default_factory = Config ) _storage : Storage = field ( default_factory = Storage ) _outbox_strategy : InMemoryOutboxStorageStrategy | None = None _subscription_strategy : InMemorySubscriptionStrategy = field ( init = False ) def __post_init__ ( self ) -> None : self . _subscription_strategy = InMemorySubscriptionStrategy ( self . _storage ) def build ( self ) -> TransactionalBackend : backend = TransactionalBackend () backend . serde = self . serde backend . in_transaction = Dispatcher ( backend . serde ) backend . event_store = EventStore ( InMemoryStorageStrategy ( self . _storage , backend . in_transaction , self . _outbox_strategy , ), backend . serde , ) backend . outbox = Outbox ( self . _outbox_strategy or NoOutboxStorageStrategy (), backend . serde , ) backend . subscriber = subscription . SubscriptionBuilder ( _serde = backend . serde , _strategy = self . _subscription_strategy , ) return backend def with_event_registry ( self , event_registry : EventRegistry ) -> Self : self . serde = Serde ( event_registry ) return self def with_outbox ( self , filterer : OutboxFiltererStrategy = no_filter ) -> Self : self . _outbox_strategy = InMemoryOutboxStorageStrategy ( filterer , self . _config . outbox_attempts , ) return self def without_outbox ( self , filterer : OutboxFiltererStrategy = no_filter ) -> Self : self . _outbox_strategy = None return self","title":"InMemoryBackendFactory"},{"location":"reference/stream_id/","text":"Bases: StreamUUID Source code in event_sourcery/event_store/stream_id.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 @dataclass ( frozen = True , repr = False , eq = False ) class StreamId ( StreamUUID ): category : Category | None = None def __repr__ ( self ) -> str : return ( f \" { type ( self ) . __name__ } \" f \"(hex= { self !s} , name= { self . name } , category= { self . category } )\" ) def __eq__ ( self , other : Any ) -> bool : if isinstance ( other , StreamId ): return super () . __eq__ ( other ) and self . category == other . category return NotImplemented def __hash__ ( self ) -> int : return hash (( self . category , super () . __hash__ ()))","title":"StreamId"},{"location":"reference/wrapped_event/","text":"Bases: BaseModel , Generic [ TEvent ] Wrapper for events with all relevant metadata. Returned from EventStore when loading events from a stream. Example usage: class OrderCancelled(Event): order_id: OrderId event = OrderCancelled(order_id=OrderId(\"#123\")) wrapped_event = WrappedEvent.wrap(event, version=1) Source code in event_sourcery/event_store/event/dto.py 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 class WrappedEvent ( BaseModel , Generic [ TEvent ], extra = \"forbid\" ): \"\"\"Wrapper for events with all relevant metadata. Returned from EventStore when loading events from a stream. Example usage: ``` class OrderCancelled(Event): order_id: OrderId event = OrderCancelled(order_id=OrderId(\"#123\")) wrapped_event = WrappedEvent.wrap(event, version=1) ``` \"\"\" event : TEvent version : int | None uuid : UUID = Field ( default_factory = uuid4 ) created_at : datetime = Field ( default_factory = datetime . utcnow ) context : Context = Field ( default_factory = Context ) @classmethod def wrap ( cls , event : TEvent , version : int | None ) -> \"WrappedEvent[TEvent]\" : return WrappedEvent [ TEvent ]( event = event , version = version )","title":"WrappedEvent"},{"location":"tutorial_eda/","text":"Event-Driven Architecture - Intro TODO","title":"Event-Driven Architecture - Intro"},{"location":"tutorial_eda/#event-driven-architecture-intro","text":"TODO","title":"Event-Driven Architecture - Intro"},{"location":"tutorial_event_sourcing/","text":"Event Sourcing - Intro TODO","title":"Event Sourcing - Intro"},{"location":"tutorial_event_sourcing/#event-sourcing-intro","text":"TODO","title":"Event Sourcing - Intro"}]}